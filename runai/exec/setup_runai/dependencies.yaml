name: file_configuration
config_values:
  namespace: matrix-benchmarking
  runai_project: hello
  runai_config_file:
  instance_type: p3.2xlarge
  instance_count: 1
---
name: has_everything
spec:
  requirements:
  - has_cluster_prepared
  - has_runai
  - has_runai_system_nodes
  - has_runai_namespace
---
name: has_cluster_prepared
spec:
  requirements:
  - library.gpu.has_pci_gpu
  - library.gpu-operator.has_gpu_operator
---
name: has_runai
spec:
  requirements:
  - has_runai_config_file
  - doesnt_have_nvidia_dcgm_exporter
  - has_runai_operator
  - has_runai_device_plugin
---
name: has_runai_system_nodes
spec:
  requirements:
  - library.gpu.has_pci_gpu
  test:
  - name: has_runai_system_nodes
    type: shell
    spec: oc get nodes -lnode-role.kubernetes.io/runai-system -oname | grep .
  install:
  - name: set_runai_system_node
    type: shell
    spec: |
      gpu_node=$(oc get nodes -lfeature.node.kubernetes.io/pci-10de.present -ojsonpath={.items[0].metadata.name})
      runai-adm set node-role --runai-system-worker $gpu_node
---
name: has_runai_config_file
spec:
  configuration:
  - runai_config_file
  test:
  - name: has_runai_config_file
    type: shell
    spec: file "$runai_config_file"
  install:
  - name: cannot_find_config_file
    type: shell
    spec: |
      echo "'runai_config_file' setting must point to the file generated by app.run.ai"
      false
---
name: has_runai_operator
spec:
  configuration:
  - runai_config_file
  test:
  - name: has_runai_crd
    type: shell
    spec: oc get crd/runaijobs.run.ai -oname
  install:
  - name: install_runai
    type: shell
    spec: |
      # from https://app.run.ai/clusters <> new cluster
      oc create namespace runai --dry-run=client -oyaml | oc apply -f-
      oc label namespace runai openshift.io/cluster-monitoring=true --overwrite

      helm repo add runai https://run-ai-charts.storage.googleapis.com
      helm repo update
      # disable namespace creation by Run:AI, we do it ourselves
      yq --in-place --yaml-roundtrip '(."runai-operator".config."project-controller".createNamespaces = false)' "${runai_config_file}"

      helm upgrade -i runai-cluster runai/runai-cluster -n runai -f "${runai_config_file}"
---
name: has_runai_namespace
spec:
  configuration:
  - namespace
  - runai_project
  test:
  - name: create_namespace
    type: shell
    spec: oc get ns -l runai/queue=$runai_project -oname | grep namespace/$namespace"$"
  install:
  - name: create_namespace
    type: shell
    spec: oc create ns $namespace || true
  - name: label the project for run.ai
    type: shell
    spec: oc label ns/$namespace runai/queue=$runai_project --overwrite

---
name: has_runai_device_plugin
spec:
  test:
  - name: has_runai_device_plugin_configured
    type: shell
    spec: test $(oc get clusterpolicy/gpu-cluster-policy -ojsonpath={.spec.devicePlugin.repository}) == "gcr.io/run-ai-prod"
  install:
  - name: set_runai_device_plugin
    type: shell
    spec: |
      oc create clusterrolebinding --clusterrole=admin --serviceaccount=nvidia-gpu-operator:nvidia-device-plugin nvidia-device-plugin-crb
      oc patch clusterpolicy/gpu-cluster-policy --type='json' -p='[{"op": "replace", "path": "/spec/devicePlugin/repository", "value": "gcr.io/run-ai-prod"}]'
      oc patch clusterpolicy/gpu-cluster-policy --type='json' -p='[{"op": "replace", "path": "/spec/devicePlugin/image", "value": "nvidia-device-plugin"}]'
      oc patch clusterpolicy/gpu-cluster-policy --type='json' -p='[{"op": "replace", "path": "/spec/devicePlugin/version", "value": "1.0.11"}]'
---
name: doesnt_have_nvidia_dcgm_exporter
spec:
  test:
  - name: doesnt_have_nvidia_dcgm_exporter
    type: shell
    spec: test -z "$(oc get nodes -lnvidia.com/gpu.deploy.dcgm-exporter=true -oname)"
  install:
  - name: disable_nvidia_dcgm_exporter
    type: shell
    spec: |
      for node in $(oc get nodes -lnvidia.com/gpu.deploy.dcgm-exporter=true -oname); do
        oc label $node nvidia.com/gpu.deploy.dcgm-exporter=runai --overwrite
      done
